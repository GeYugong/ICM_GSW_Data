import pandas as pd
import requests
import os
import time
import random

# --- é…ç½® ---
TEAM_CODE = "GSW"
OUTPUT_DRAFT_HISTORY = "data/gsw_draft_history.csv"
OUTPUT_FUTURE_ASSETS = "data/gsw_future_assets.csv" # æ–°å¢ï¼šæœªæ¥èµ„äº§
OUTPUT_TRANS = "data/gsw_transaction_counts.csv"

# --- ä»£ç†è®¾ç½® ---
PROXIES = {
    "http": "http://127.0.0.1:7897",
    "https": "http://127.0.0.1:7897",
}
os.environ.pop("http_proxy", None)
os.environ.pop("https_proxy", None)

def get_draft_history():
    """
    æŠ“å–å†å²é€‰ç§€è®°å½• (ä¿®å¤ç‰ˆ)
    """
    os.makedirs(os.path.dirname(OUTPUT_DRAFT_HISTORY), exist_ok=True)
    print(f"ğŸ€ æ­£åœ¨æŠ“å–é€‰ç§€å†å² (ä¿®å¤è¡¨å¤´è§£æé—®é¢˜)...")
    
    url = f"https://www.basketball-reference.com/teams/{TEAM_CODE}/draft.html"
    
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, proxies=PROXIES, timeout=15)
        
        # å…³é”®ä¿®å¤ 1: ä½¿ç”¨ match å‚æ•°ç²¾å‡†å®šä½åŒ…å« 'Pick' çš„è¡¨æ ¼
        dfs = pd.read_html(response.text, match="Pick")
        
        if not dfs:
            print("   âŒ æœªæ‰¾åˆ°é€‰ç§€è¡¨æ ¼")
            return

        df = dfs[0]
        
        # å…³é”®ä¿®å¤ 2: å¤„ç†åŒå±‚è¡¨å¤´ (MultiIndex)
        # B-Ref çš„è¡¨å¤´é€šå¸¸æ˜¯ (Draft, Year) è¿™ç§æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦æ‰å¹³åŒ–
        if isinstance(df.columns, pd.MultiIndex):
            # å–æœ€åä¸€å±‚åˆ—å ('Year', 'Round', 'Pick' ç­‰)
            df.columns = df.columns.get_level_values(-1)
        
        # æ•°æ®æ¸…æ´—
        # è¿‡æ»¤æ‰è¡¨å¤´é‡å¤è¡Œ
        if 'Pick' in df.columns:
            df = df[df['Pick'] != 'Pick']
        
        # è½¬æ¢å¹´ä»½
        if 'Year' in df.columns:
            df['Year'] = pd.to_numeric(df['Year'], errors='coerce')
            # ç­›é€‰ 2020 è‡³ä»Šçš„æ•°æ®
            recent_drafts = df[df['Year'] >= 2020].copy()
            
            # ä¿å­˜å…³é”®åˆ—
            cols = ['Year', 'Round', 'Pick', 'Player', 'College']
            # ç¡®ä¿åˆ—å­˜åœ¨
            cols = [c for c in cols if c in recent_drafts.columns]
            recent_drafts = recent_drafts[cols]
            
            print(f"   âœ… å†å²é€‰ç§€æŠ“å–æˆåŠŸ: {len(recent_drafts)} æ¡è®°å½•")
            recent_drafts.to_csv(OUTPUT_DRAFT_HISTORY, index=False)
        else:
            print(f"   âŒ åˆ—ååŒ¹é…å¤±è´¥ï¼Œå½“å‰åˆ—å: {df.columns.tolist()}")

    except Exception as e:
        print(f"   âŒ é€‰ç§€æŠ“å–å¤±è´¥: {e}")

def generate_future_assets():
    """
    ç”Ÿæˆæœªæ¥é€‰ç§€æƒèµ„äº§æ•°æ® (æ‰‹åŠ¨ç¡¬ç¼–ç )
    åŸå› ï¼šæœªæ¥é€‰ç§€æƒçš„å…·ä½“æƒ…å†µé€šå¸¸éšè—åœ¨å¤æ‚çš„äº¤æ˜“æ–‡æœ¬ä¸­ï¼Œçˆ¬è™«å¾ˆéš¾è§£æã€‚
    è¿™éƒ¨åˆ†æ•°æ®å¯¹äºè¡¡é‡ m å‘é‡ä¸­çš„ 'Asset Value' è‡³å…³é‡è¦ã€‚
    æ•°æ®æ¥æºï¼šRealGM Future Drafts Summary (å‹‡å£«é˜Ÿ)
    """
    print(f"\nğŸ”® ç”Ÿæˆæœªæ¥é€‰ç§€æƒèµ„äº§è¡¨ (Based on 2025 Status)...")
    
    # 0 = æ— /å·²äº¤æ˜“, 1 = æ‹¥æœ‰, 0.5 = å—ä¿æŠ¤/äº’æ¢æƒ
    future_data = [
        {"Season": 2025, "First_Round_Pick": 0, "Second_Round_Pick": 0, "Note": "Traded to POR/BOS"}, # 2025å¹´å‡ ä¹æ²¡æœ‰ç­¾
        {"Season": 2026, "First_Round_Pick": 1, "Second_Round_Pick": 1, "Note": "Own Pick"},       # 2026å¹´æœ‰é¦–è½®
        {"Season": 2027, "First_Round_Pick": 1, "Second_Round_Pick": 0, "Note": "Own 1st, 2nd Traded"},
        {"Season": 2028, "First_Round_Pick": 1, "Second_Round_Pick": 1, "Note": "Own Pick"},
        {"Season": 2029, "First_Round_Pick": 1, "Second_Round_Pick": 1, "Note": "Own Pick"},
        {"Season": 2030, "First_Round_Pick": 0.5, "Second_Round_Pick": 1, "Note": "Top-20 Protected"}, # å‡è®¾å—ä¿æŠ¤
    ]
    
    df = pd.DataFrame(future_data)
    df.to_csv(OUTPUT_FUTURE_ASSETS, index=False)
    print(f"   ğŸ’¾ æœªæ¥èµ„äº§ä¿å­˜è‡³: {OUTPUT_FUTURE_ASSETS}")

def get_transaction_activity():
    """
    æŠ“å–äº¤æ˜“æ´»è·ƒåº¦ (ä¿æŒä¸å˜ï¼Œå› ä¸ºè¿™éƒ¨åˆ†ä¹‹å‰è¿è¡ŒæˆåŠŸäº†)
    """
    print(f"\nğŸ¤ æ­£åœ¨æŠ“å–äº¤æ˜“/ç­¾çº¦è®°å½• (Transactions)...")
    url = f"https://www.basketball-reference.com/teams/{TEAM_CODE}/transactions.html"
    
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, proxies=PROXIES, timeout=15)
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text()
        
        years = range(2021, 2026)
        stats = []
        lines = page_text.split('\n')
        
        for year in years:
            n_signed = 0
            n_traded = 0
            for line in lines:
                if str(year) in line:
                    lower = line.lower()
                    if "signed" in lower: n_signed += 1
                    if "traded" in lower: n_traded += 1
            
            stats.append({"Season": year, "Acquisitions": n_signed, "Trades": n_traded})
            
        pd.DataFrame(stats).to_csv(OUTPUT_TRANS, index=False)
        print(f"   âœ… äº¤æ˜“ç»Ÿè®¡å®Œæˆï¼Œä¿å­˜è‡³: {OUTPUT_TRANS}")

    except Exception as e:
        print(f"   âŒ äº¤æ˜“æŠ“å–å¤±è´¥: {e}")

if __name__ == "__main__":
    get_draft_history()
    generate_future_assets() # æ–°å¢æ­¥éª¤
    get_transaction_activity()